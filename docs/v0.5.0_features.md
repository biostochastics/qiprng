# qiprng v0.5.0 Feature Documentation

## Overview

Version 0.5.0 introduces significant performance enhancements and new capabilities to the qiprng package, focusing on hardware acceleration, parallel generation, and advanced mixing strategies.

## New Features

### 1. Advanced Mixing Strategies

The MultiQI ensemble now supports five different mixing strategies for combining outputs from multiple quadratic irrational generators:

```r
# Available mixing strategies
cfg <- list(
  mixing_strategy = "xor_mix"  # Options below
)

# Strategies:
# - "round_robin": Sequential cycling through generators (default)
# - "xor_mix": Bitwise XOR of mantissas for maximum entropy
# - "averaging": Weighted average for smooth distribution
# - "modular_add": Sum modulo 1 for entropy combining
# - "cascade_mix": Three-pass mixing (XOR → modular → nonlinear)
```

**Performance Characteristics:**
- `round_robin`: Fastest, good for general use
- `xor_mix`: Best entropy, recommended for cryptographic applications
- `averaging`: Smoothest distribution, good for simulations
- `modular_add`: Good balance of speed and quality
- `cascade_mix`: Maximum randomness, slightly slower

### 2. Parallel Generation Framework

Enable parallel buffer filling for improved performance on multi-core systems:

```r
cfg <- list(
  use_parallel_filling = TRUE,  # Enable parallel generation
  buffer_size = 100000          # Large buffer for efficiency
)
```

**Features:**
- Work-stealing queue for dynamic load balancing
- Automatic thread count optimization
- Thread-safe buffer management
- Scales linearly up to 8 cores

### 3. SIMD Vectorization

Hardware-optimized operations are automatically enabled based on CPU capabilities:

- **x86_64**: AVX2 (4 doubles/op) or AVX512 (8 doubles/op)
- **ARM64/Apple Silicon**: NEON (2 doubles/op)
- **Fallback**: Scalar operations on unsupported platforms

No configuration needed - SIMD is detected and used automatically.

### 4. Matrix Jump-Ahead

Create independent parallel streams efficiently:

```r
# Create base configuration
cfg <- list(
  a = 2, b = 5, c = -2,
  seed = 12345
)

# Generate first stream
createPRNG(cfg)
stream1 <- generatePRNG(10000)
cleanup_prng()

# Jump ahead for independent stream
cfg$offset <- 1000000  # Jump 1M values ahead
createPRNG(cfg)
stream2 <- generatePRNG(10000)
cleanup_prng()

# Streams are statistically independent
cor(stream1, stream2)  # Should be near 0
```

**Algorithm:**
- O(log n) complexity using matrix exponentiation
- MPFR precision for numerical stability
- Supports jumps up to 2^64 values

### 5. Hardware Acceleration Support

The package automatically detects and uses available hardware features:

```r
# Check your system's capabilities
library(qiprng)
parallel::detectCores()  # Number of CPU cores

# OpenMP parallelization (if available)
cfg <- list(
  use_parallel_filling = TRUE,
  use_threading = TRUE
)
```

**Supported Accelerations:**
- OpenMP for multi-core parallelization
- SIMD instructions (AVX2, AVX512, NEON)
- Thread-local storage for concurrent access
- Memory pooling for MPFR allocations

## Performance Guidelines

### Buffer Size Selection

```r
# Small datasets (< 10K values)
cfg <- list(buffer_size = 1000)

# Medium datasets (10K - 1M values)  
cfg <- list(buffer_size = 10000)

# Large datasets (> 1M values)
cfg <- list(
  buffer_size = 100000,
  use_parallel_filling = TRUE
)
```

### Mixing Strategy Selection

| Use Case | Recommended Strategy | Reason |
|----------|---------------------|---------|
| General purpose | `round_robin` | Fast, good quality |
| Cryptographic | `xor_mix` | Maximum entropy |
| Monte Carlo | `averaging` | Smooth distribution |
| High security | `cascade_mix` | Best randomness |
| Performance critical | `round_robin` | Minimal overhead |

### Platform-Specific Optimization

**Apple Silicon (M1/M2/M3):**
```r
cfg <- list(
  use_parallel_filling = FALSE,  # Single-threaded often faster
  buffer_size = 50000,           # Optimal for unified memory
  mixing_strategy = "xor_mix"    # NEON-optimized
)
```

**Intel/AMD x86_64:**
```r
cfg <- list(
  use_parallel_filling = TRUE,   # Leverage multiple cores
  buffer_size = 100000,          # Large L3 cache
  mixing_strategy = "cascade_mix" # AVX2-optimized
)
```

## Benchmarks

Performance on Apple Silicon M1 (10 CPU cores):

| Operation | Size | Time | Rate |
|-----------|------|------|------|
| Sequential | 100K | 0.95s | 105K/s |
| Parallel (4 threads) | 100K | 0.28s | 357K/s |
| SIMD XOR mixing | 100K | 0.31s | 323K/s |
| Jump-ahead (1M) | - | 0.02s | - |

## Migration Guide

### From v0.4.x to v0.5.0

No breaking changes - existing code continues to work. To use new features:

```r
# Old code (still works)
createPRNG()
vals <- generatePRNG(10000)

# Enhanced with v0.5.0 features
cfg <- list(
  mixing_strategy = "xor_mix",     # New: advanced mixing
  use_parallel_filling = TRUE,     # New: parallel generation
  buffer_size = 100000             # Larger buffers now efficient
)
createPRNG(cfg)
vals <- generatePRNG(1000000)  # Much faster!
```

### Best Practices

1. **Always clean up**: Call `cleanup_prng()` when done
2. **Use appropriate buffer sizes**: Match your data size
3. **Enable parallel only for large datasets**: Overhead for small sets
4. **Test deterministic mode**: Use seeds for reproducibility
5. **Profile your use case**: Different strategies for different needs

## Troubleshooting

### Parallel generation seems slow

- Disable for small datasets (< 10K values)
- Check CPU core count: `parallel::detectCores()`
- Try different mixing strategies

### Memory usage is high

- Reduce buffer size
- Disable parallel filling
- Use `cleanup_prng()` between runs

### Results differ between runs

- Set a seed for reproducibility: `cfg$seed <- 12345`
- Ensure `deterministic = TRUE` if needed
- Check thread safety settings

## Technical Details

### Work-Stealing Algorithm

The parallel generation uses a work-stealing queue where idle threads can "steal" work from busy threads:

1. Work divided into chunks (4x thread count)
2. Each thread has local queue
3. Idle threads steal from back of busy queues
4. Automatic load balancing

### SIMD Implementation

Vectorized operations for:
- XOR mixing of mantissas
- Weighted averaging
- Batch normalization
- Memory copies

### Thread Safety

- Thread-local QI instances
- Lock-free memory pooling
- Atomic operations for counters
- Mutex protection for shared state

## Future Enhancements

Planned for v0.6.0:
- GPU acceleration (CUDA/Metal)
- Extended distribution support in R interface
- Distributed generation (MPI)
- Quantum-inspired mixing strategies