---
title: "Mathematical Theory"
description: "Mathematical foundations of quadratic irrational PRNGs"
sidebarTitle: "Theory"
---

# Technical Documentation for the Quadratic Irrational PRNG v0.5.0

 **Attribution Note**: The mathematical foundation and core algorithm design presented in this document is based on the amazing work of Vincent Granville (2024), specifically his research on military-grade random number generators using quadratic irrationals that I ran into in the dead of night after having way too much coffee. While Granville provided the original Python implementation, this doc describes my R/C++ implementation developed primarily for educational purposes. Cool if you find it useful. Even better if you find a bug!

 **Reference**: Granville, V. (2022). Synthetic Data and Generative AI 1st Edition. <https://mltechniques.com/2022/12/13/military-grade-fast-random-number-generator-based-on-quadratic-irrationals/>

## Version 0.5.0 Enhancements

### Matrix Jump-Ahead with O(log n) Complexity

The v0.5.0 implementation includes an optimized jump-ahead algorithm using matrix exponentiation:

```cpp
// Matrix representation of the quadratic map
[ x_{n+1} ]   [ a  b  c ] [ x_n^2 ]
[ x_n     ] = [ 1  0  0 ] [ x_n   ]
[ 1       ]   [ 0  0  1 ] [ 1     ]
```

Using binary exponentiation, we can compute M^n in O(log n) operations, enabling efficient parallel stream generation.

### Advanced Mixing Strategies

Five mixing strategies combine outputs from multiple QI generators:

1. **Round Robin**: Sequential cycling through generators
2. **XOR Mixing**: Bitwise XOR of mantissas for maximum entropy
3. **Averaging**: Weighted average for smooth distribution
4. **Modular Addition**: Sum modulo 1 for entropy combining
5. **Cascade Mixing**: Three-pass mixing (XOR → modular → nonlinear)

### SIMD Vectorization

Hardware-optimized operations using:

- **AVX2/AVX512**: 4-8 doubles per operation on x86
- **ARM NEON**: 2 doubles per operation on Apple Silicon
- **Automatic fallback**: Scalar operations when SIMD unavailable

## 1. Mathematical Foundation: The Quadratic Map

### 1.1 Basic Principle

The core algorithm, as described by Granville (2024), is based on a quadratic recurrence relation of the form:

```
x_{n+1} = (a*x_n^2 + b*x_n + c) mod 1
```

Where:

- `x_n` is the current state (a value in [0,1])
- `a`, `b`, and `c` are integer parameters
- `mod 1` means we take the fractional part of the result

This is a discrete dynamical system derived from the theory of quadratic irrationals. When properly configured, this map exhibits chaotic behavior, making it suitable for random number generation.

### 1.2 The Discriminant Requirement

The discriminant of the quadratic equation is defined as:

```
Δ = b² - 4ac
```

**Why the discriminant must be positive:**

1. **Mathematical reasons**: A positive discriminant ensures that the quadratic equation `ax² + bx + c = 0` has two distinct real roots. This is essential because:

   - When Δ > 0, the quadratic map has two fixed points in the real domain
   - These fixed points create a bounded region where chaotic behavior occurs
   - The sequence will "bounce" unpredictably between these boundaries

2. **Randomness quality**: When the discriminant is positive, the sequence exhibits sensitive dependence on initial conditions (the "butterfly effect"), a hallmark of chaotic systems that produces high-quality randomness.

3. **Sequence behavior**:
   - Negative discriminant: The sequence would converge to a predictable pattern
   - Zero discriminant: The sequence would gravitate toward a single fixed point
   - Only a positive discriminant creates the necessary "stretching and folding" dynamic for chaos

### 1.3 Orbit Structure

The sequence generated by this recurrence relation creates what mathematicians call an "orbit" in dynamical systems theory. With proper parameters, this orbit:

- Densely fills the interval [0,1]
- Never repeats exactly (with sufficient precision)
- Has a uniform distribution of points
- Exhibits exponential divergence of nearby starting values

## 2. Parameter Constraints and Their Reasoning

### 2.1 Parameter `a`

**Constraint**: `a > 0` (must be positive)

**Reasoning**:

- Controls the "stretching" factor of the map
- If negative, would invert the parabola and destroy the chaotic properties
- If zero, would degenerate into a linear map with poor randomness

### 2.2 Parameter `c`

**Constraint**: `c < 0` (must be negative)

**Reasoning**:

- Together with `a > 0`, ensures the parabola crosses the x-axis in the right places
- Creates the correct topology for the chaotic attractor
- Ensures the mapping stays within [0,1] after taking the fractional part

### 2.3 Discriminant: `b² - 4ac > 0`

**Reasoning**:

- As explained above, ensures two real fixed points
- Creates the mathematical foundation for chaotic behavior
- Prevents the sequence from falling into simple patterns

### 2.4 Parameter Selection Guidelines

For optimal randomness properties:

1. **Coprime values**: Ideally, parameters `a`, `b`, and `c` should be coprime (no common divisors)
2. **Moderate values**: While any valid values will work mathematically, moderate values (e.g., 1-10) are more numerically stable
3. **High precision**: Higher MPFR precision increases the period length and quality of randomness

## 3. MultiQI Implementation (v0.5.0 Enhanced)

### 3.1 Mixing Strategies

Version 0.5.0 introduces configurable mixing strategies for combining multiple QI sequences:

1. **Round-Robin** (Default):
   - Cycles through sequences sequentially
   - Lowest computational overhead
   - Good for general-purpose applications

2. **XOR Mixing**:
   - Combines outputs via bitwise XOR of mantissas
   - Excellent bit diffusion properties
   - Ideal for cryptographic applications

3. **Averaging**:
   - Averages outputs from all QI sequences
   - Smooths distribution characteristics
   - Reduces individual sequence biases

4. **Modular Addition**:
   - Adds outputs modulo 1
   - Preserves uniform distribution
   - Good entropy mixing

5. **Cascade Mixing**:
   - Feeds output of one QI as input to next
   - Maximum entropy diffusion
   - Highest security but slower performance

### 3.2 Mathematical Benefits

Each mixing strategy provides different theoretical advantages:

- **Period extension**: Effective period up to LCM of individual periods
- **Entropy amplification**: Multiple sources increase unpredictability
- **Bias reduction**: Averaging reduces systematic biases
- **Correlation breaking**: XOR destroys linear correlations

### 3.2 Parameter Diversification

The implementation uses a carefully selected set of (a,b,c) parameters:

1. **Parameter selection**:
   - Parameters are chosen to have positive discriminants
   - Different parameters create sequences with different orbital characteristics
   - Parameter selection affects the "mixing speed" of the sequence

2. **Random skipping**:
   - Each QI sequence is initialized and then skipped a random number of steps
   - This ensures different starting points even with the same parameters
   - Prevents potential synchronization of sequences

3. **Manual Multi-QI Configuration** (v0.5.0):
   - Users can specify multiple QI parameters directly via vectors
   - Example: `a = c(2, 3, 5), b = c(7, 11, 13), c = c(-3, -5, -7)`
   - Each triplet (a[i], b[i], c[i]) defines a separate QI generator
   - All discriminants are validated to ensure mathematical correctness
   - Supports 2-16 simultaneous QI generators for optimal performance

### 3.3 Custom Discriminants via CSV

The implementation supports using custom discriminants from a CSV file:

1. **Mathematical advantages of custom discriminants**:
   - **Optimized orbital characteristics**: Carefully chosen discriminants can produce sequences with improved statistical properties
   - **Controlled cycle lengths**: Different discriminants lead to different cycle lengths, allowing optimization for specific applications
   - **Spectral properties**: The discriminant value directly influences the spectral properties of the sequence, with certain values producing better results in frequency domain tests
   - **Greater unpredictability**: Custom discriminants can enhance the unpredictability of the sequence, making it harder to reverse-engineer

2. **Selection criteria for optimal discriminants**:
   - **Prime or prime-rich factorizations**
   - **Congruence classes**
   - **Large discriminants**
   - **Spectral testing**: Discriminants that perform well on spectral tests minimize periodic patterns

3. **Implementation advantages**:
   - **Customization**: Users can tune the PRNG to specific application requirements
   - **Reproducibility**: Custom discriminants allow for reproducible sequences across different environments
   - **Parallel independence**: Using different discriminants for parallel streams ensures statistical independence
   - **Domain-specific optimization**: Applications with special requirements can benefit from discriminants optimized for those needs

4. **Usage example**:

   ```
   # Content of discriminants.csv
   a,b,c,Discriminant
   1,9,-143,653
   1,9,-145,661
   1,9,-148,673
   1,9,-149,677
   1,11,-145,701
   ...
   ```

   The CSV file provides complete (a,b,c) triplets along with their calculated discriminant values (b² - 4ac). This format allows for direct specification of parameters known to have desirable properties, rather than deriving them from discriminants alone.

By default the package uses only the 370 "Excellent" discriminants obtained using testing the 750 discriminants provided with the package.

## 4. Matrix Jump-Ahead Algorithm (v0.5.0)

### 4.1 Mathematical Foundation

The quadratic map can be represented in matrix form. Given the recurrence:

```
x_{n+1} = (a*x_n^2 + b*x_n + c) mod 1
```

For the linearized form around the orbit, we can express transformations as:

```
[x_{n+1}]   [p q] [x_n]
[   1   ] = [0 1] [ 1 ]
```

Where p and q depend on the specific transformation parameters.

### 4.2 Binary Exponentiation

To jump ahead by n steps, we compute the nth power of the transformation matrix using binary exponentiation:

```
Matrix^n = Matrix^(b_k * 2^k + ... + b_1 * 2 + b_0)
         = Matrix^(b_k * 2^k) * ... * Matrix^(b_1 * 2) * Matrix^b_0
```

This reduces complexity from O(n) to O(log n) matrix multiplications.

### 4.3 MPFR Precision Preservation

All matrix operations use MPFR arithmetic to maintain full precision:

- Matrix multiplication preserves exact values
- Modular reduction maintains fractional precision
- No accuracy loss even for astronomical jumps (10^18 steps)

## 5. CFE Period Detection (v0.5.0)

### 5.1 Continued Fraction Expansion

For quadratic irrationals of the form:

```
α = (√D + P) / Q
```

The continued fraction expansion is:

```
α = a_0 + 1/(a_1 + 1/(a_2 + 1/(...)))
```

### 5.2 Gauss-Legendre Algorithm

The package implements the Gauss-Legendre algorithm for O(L) period detection:

1. **Initialization**: Start with P_0 = 0, Q_0 = 1
2. **Iteration**:

   ```
   a_n = floor((√D + P_n) / Q_n)
   P_{n+1} = a_n * Q_n - P_n
   Q_{n+1} = (D - P_{n+1}^2) / Q_n
   ```

3. **Period detection**: When (P_n, Q_n) repeats, period is found

### 5.3 Complexity Analysis

- **Time complexity**: O(L) where L is the period length
- **Space complexity**: O(L) to store the period
- **Practical performance**: Periods typically < 1000 for discriminants < 10^6

## 6. Dynamic QI Generation (v0.5.0)

### 6.1 Discriminant Pattern

The package uses discriminants of the form D = k² + 1:

- Always square-free (cannot be divided by any perfect square)
- Produces well-distributed quadratic irrationals
- Efficient validation: check if D - 1 is a perfect square

### 6.2 Square-Free Validation

Algorithm for checking square-free property:

```
is_square_free(D):
  for p in small_primes:
    if D % (p*p) == 0:
      return false
  return true
```

### 6.3 Benefits

- **Guaranteed quality**: Square-free discriminants avoid degenerate cases
- **Efficient generation**: O(sqrt(D)) validation time
- **Good distribution**: k² + 1 pattern covers discriminant space well

## 7. Cryptographic Mixing

### 7.1 Purpose and Motivation

While the quadratic irrational generator produces sequences with good statistical properties, adding cryptographic mixing provides:

1. **Enhanced statistical quality**: Eliminates subtle patterns that might exist in the raw sequence
2. **Cryptographic security**: Makes the output suitable for cryptographic applications
3. **Defense against analysis**: Prevents potential mathematical analysis of the underlying sequence

### 7.2 Mixing Approaches

The package implements two different approaches for cryptographic mixing:

#### 7.2.1 Partial Modular Addition (Default)

```
x_mixed = (x_original + crypto_uniform) mod 1
```

Where:

- `x_original` is the raw value from the quadratic irrational generator
- `crypto_uniform` is a cryptographically secure random value in [0,1)
- The result is taken modulo 1 to keep it in [0,1)

**Benefits**:

- Preserves the uniform distribution
- Cryptographically strong
- Efficiently eliminates patterns in the original sequence

#### 7.2.2 Partial Averaging (Alternative)

An alternative approach that uses weighted averaging instead of modular addition, activated with the `adhoc_corrections` flag:

```
x_mixed = (x_original + crypto_uniform) / 2
```

**Differences**:

- May provide slight differences in statistical behavior
- Included as an alternative mixing strategy for testing

### 4.3 Integration with Core Generator

The cryptographic mixing integrates with the core generator in several ways:

1. **Buffer-based processing**:
   - Values are generated in buffers for efficiency
   - Entire buffers are cryptographically processed at once

2. **Reseeding mechanism**:
   - Both the quadratic parameters and the encryption key are replaced during reseeding
   - Reseeding can occur automatically after a specified number of generated values

3. **Careful handling of sensitive data**:
   - Encryption keys are stored in secure memory
   - Keys are properly zeroed when no longer needed using sodium_memzero
   - Side-channel mitigation techniques are employed

### 4.4 Tie-Breaking Mechanism

The implementation includes a tie-breaking mechanism to handle the rare case of duplicate consecutive values:

1. **Detection**:
   - Checks if the current output exactly equals the previous output
   - Such exact duplications are extremely rare but possible

2. **Resolution**:
   - Adds a tiny random epsilon value to break the tie
   - The epsilon is small enough not to affect the distribution
   - Ensures consecutive identical values never occur

3. **Benefits**:
   - Prevents potential issues in applications that expect unique values
   - Provides additional entropy in edge cases
   - Maintains the overall statistical properties

## 5. Distribution Transformations

The raw uniform [0,1] values can be transformed into various probability distributions:

### 5.1 Uniform Range

Transforms uniform [0,1] to uniform [min, max]:

```
y = min + x*(max - min)
```

### 5.2 Normal Distribution

Uses the Box-Muller transform to generate normally distributed values:

```
r = sqrt(-2*ln(u1))
θ = 2π*u2
x = mean + sd * r*cos(θ)
y = mean + sd * r*sin(θ)
```

Where u1 and u2 are independent uniform [0,1] values. The implementation optimizes this by storing the second value (y) for the next call, effectively using both random numbers generated from each pair of uniform draws.

### 5.3 Exponential Distribution

Uses the inverse transform method:

```
x = -ln(1-u)/λ
```

Where u is a uniform [0,1] value and λ is the rate parameter.

## 6. Precision and Numerical Considerations

### 6.1 MPFR Precision

The package uses the GNU MPFR library for arbitrary-precision arithmetic:

- **Default**: 53 bits (equivalent to double precision)
- **Range**: 24 to 10,000 bits (package limit)
- **Impact**: Higher precision increases cycle length and improves statistical properties

### 6.2 Numerical Stability

Considerations for numerical stability:

- **Overflow protection**: All calculations use arbitrary precision to prevent overflow
- **Underflow handling**: Special handling for values close to zero
- **Modular reduction**: Exact fractional part calculation ensures values stay in [0,1)

### 6.3 Period Length

With sufficient precision, the period length of the generator is extremely long:

- At 53-bit precision: effectively non-repeating for practical applications
- At higher precisions: period grows exponentially
- With cryptographic mixing: period becomes cryptographically large

### 6.4 Fixed Point Avoidance

A critical consideration in the implementation is avoiding fixed points. A fixed point is a value x where f(x) = x, meaning the sequence would get stuck at this value.

**Issues with Fixed Points:**

- Early implementations using the fractional part of 1/(ax + b) could converge to fixed points (e.g., 0.1861407...)
- Once convergence occurs, random numbers are no longer generated, as all subsequent values are identical
- This severely impacts the statistical properties and utility of the PRNG

**Solution:**

1. The current implementation uses the full quadratic map (ax² + bx + c mod 1)
2. The choice of parameters (a>0, c<0) ensures no fixed points in [0,1]
3. Even if a fixed point were approached, cryptographic mixing would move the state away
4. Random initial values and seeding further prevent fixed point convergence

## 7. Thread Safety and Parallelism

### 7.1 Thread Safety Mechanisms

The package provides two approaches to thread safety:

1. **Global Mutex Protection**:
   - When `use_threading = FALSE` (default)
   - A global mutex protects access to the PRNG state
   - Ensures only one thread can access the PRNG at a time
   - Guarantees sequence reproducibility but may limit parallelism

2. **Thread-Local Instances**:
   - When `use_threading = TRUE`
   - Each thread gets its own independent PRNG instance
   - No mutex contention, allowing full parallelism
   - Different random sequences in each thread

### 7.2 Mathematical Implications of Threading

Using thread-local PRNG instances has important mathematical implications:

1. **Independence**:
   - Sequences generated in different threads are statistically independent
   - No correlation between sequences across threads
   - Reduces potential for pattern emergence in parallel applications

2. **Reproducibility**:
   - With global mutex: sequence is reproducible regardless of threading
   - With thread-local instances: each thread's sequence is reproducible but different
   - Important consideration for scientific computing and simulation

3. **Performance vs. Determinism**:
   - Thread-local instances offer better performance but less predictability
   - Global mutex offers deterministic results but may be slower in highly threaded applications
   - Choice depends on application requirements

## 8. Secure Memory Management

### 8.1 SecureBuffer Implementation

The package uses a template class called `SecureBuffer` for secure memory management:

1. **RAII Design**:
   - Resource Acquisition Is Initialization pattern
   - Automatically handles proper cleanup of sensitive data
   - Prevents memory leaks and security vulnerabilities

2. **Secure Memory Clearing**:
   - Overwrites memory with zeros before deallocation
   - Uses volatile pointers to prevent compiler optimization
   - Ensures sensitive data (like encryption keys) is securely erased

3. **Memory Safety**:
   - Type-safe wrapper around std::vector
   - Prevents buffer overflows and memory corruption
   - Simplifies memory management throughout the codebase

### 8.2 Side-Channel Mitigation

The implementation includes several measures to reduce side-channel attack vectors:

1. **Constant-time operations** where possible
2. **Avoidance of secret-dependent control flow**
3. **Protection against timing attacks**
4. **Use of libsodium's secure memory functions**

### 8.3 Application to Sensitive Data

SecureBuffer is applied to:

- Cryptographic keys
- Nonces
- Temporary buffers containing sensitive data
- Any other security-critical components

## 9. Implementation Note on Use of SecureBuffer

The qiprng implementation uses the SecureBuffer template class for secure memory management of sensitive data. This class:

1. Provides RAII-style memory management, automatically clearing sensitive data when it goes out of scope
2. Implements a secure clearing procedure that overwrites memory with zeros before deallocation
3. Ensures that cryptographic keys and other sensitive values are properly handled

When implementing or modifying code, it's important to:

- Always use SecureBuffer for any security-sensitive data
- Avoid creating unnecessary copies of sensitive data
- Allow the SecureBuffer destructor to handle clearing instead of manual clearing
- Remember that SecureBuffer constructor takes only a size parameter, not an initializer value

## 10. Memory Management Optimizations (v0.5.0)

### 10.1 MPFR Memory Pooling

Version 0.5.0 introduces a singleton memory pool for MPFR objects:

1. **Pool Architecture**:
   - Pre-allocated pool of 1024 MPFR objects
   - Lock-free allocation using atomic operations
   - Zero-copy returns to pool

2. **Performance Benefits**:
   - Eliminates malloc/free overhead
   - Reduces memory fragmentation
   - Improves cache locality

3. **Thread Safety**:
   - Thread-safe allocation/deallocation
   - Per-thread quotas prevent starvation
   - Fallback to heap allocation when pool exhausted

### 10.2 Thread-Local Storage

Each thread maintains its own MultiQI instance:

1. **ThreadManager Singleton**:
   - Manages thread-local QI instances
   - Automatic cleanup on thread exit
   - Prevents race conditions

2. **Benefits**:
   - No mutex contention for generation
   - Better cache performance
   - Scalable to many threads

3. **Memory Efficiency**:
   - Lazy initialization per thread
   - Automatic cleanup prevents leaks
   - Shared discriminant data

## 11. Discriminants (pre-selected)

The package includes a set of pre-selected discriminants for quadratic irrationals.

### Excellent Discriminant Selection (Production Default)

**New Default Behavior**: qiprng now uses only the 370 "Excellent" rated discriminants by default, identified through comprehensive analysis.

**Selection Criteria** (all must be satisfied):

- **Autocorrelation Excellence**: `max_abs_acf ≤ 0.010`
- **Zero Significant Lags**: No autocorrelation beyond statistical/empirical thresholds
- **Multi-Test Validation**: Pass uniformity, independence, and periodicity tests

**Parameter Patterns for Excellence**:

- **Parameter `a`**: Prefer small values (1-3) for optimal performance
- **Discriminant range**: 1000-2000 shows consistently high quality
- **Parameter `c`**: Moderately negative values (-120 to -150) preferred

**Quality Assurance**: Each excellent discriminant achieved:

- Overall quality score ≥ 0.85 ("Excellent" threshold)
- Passed comprehensive statistical validation including autocorrelation, uniformity, independence, and periodicity tests
- Demonstrated stable performance across 1,000,000 sample sequences

The package includes all discriminants for research, but uses only excellent ones for production unless explicitly configured otherwise. Legacy discriminants are selected based on:

### Comprehensive Discriminant Analysis Results

**Executive Summary**: A comprehensive analysis of all 750 discriminants, each tested with 1,000,000 samples, was performed. The results confirm that while the underlying generation method is strong, rigorous testing is crucial for identifying the highest quality parameter sets.

- **370 Excellent Discriminants**: A total of 370 discriminants (49.3%) passed all tests with the highest quality rating.
- **Complete Quality Distribution**: Excellent: 370 (49.3%), Very-Good: 31 (4.1%), Good: 293 (39.1%), Fair: 50 (6.7%), Poor: 6 (0.8%)
- **Effective Discrimination**: The stricter autocorrelation test provides a more realistic distribution of results, successfully identifying minor flaws that were previously missed.
- **Overall Robustness**: 92.5% of the discriminants were rated as "Good" or better (including "Very-Good"), confirming the underlying strength of the generation method.

## 12. Performance Analysis

### 12.1 Benchmarking Results

In comprehensive benchmarks comparing qiprng with standard R generators, the following performance characteristics were observed:

| Generator | Time for 100K samples | Relative Speed | Statistical Quality |
|-----------|----------------------|----------------|-------------------|
| qiprng | ~27ms | 1x (baseline) | Excellent (cryptographic) |
| Mersenne Twister | ~0.5ms | 54x faster | Excellent (non-crypto) |
| L'Ecuyer-CMRG | ~0.9ms | 30x faster | Very Good |
| Wichmann-Hill | ~0.4ms | 68x faster | Good |

### 12.2 Computational Complexity Analysis

The performance difference stems from fundamental algorithmic differences:

#### 12.2.1 Operation Count per Random Number

**Standard Linear Congruential Generators (e.g., Mersenne Twister)**:

- 1 integer multiplication
- 1 integer addition
- 1 modulo operation (often optimized away)
- Total: ~3 simple integer operations

**qiprng Quadratic Irrational Generator**:

- 1 MPFR squaring operation (mpfr_mul)
- 2 MPFR scalar multiplications (mpfr_mul_si)
- 2 MPFR additions (mpfr_add, mpfr_add_si)
- 1 MPFR fractional part extraction (mpfr_frac)
- 1 MPFR sign check and conditional addition
- Total: ~7 arbitrary precision operations

#### 12.2.2 MPFR Overhead

Each MPFR operation involves:

- **Dynamic memory management**: Arbitrary precision requires dynamic allocation
- **Software arithmetic**: No hardware acceleration for arbitrary precision
- **Rounding control**: Each operation must respect the rounding mode
- **Exception handling**: NaN and infinity checks after each operation

Typical overhead: 100-1000x slower than hardware floating-point operations

### 12.3 Component-wise Performance Breakdown

Based on code analysis and profiling estimates:

1. **MPFR Arithmetic Operations** (~60% of runtime)
   - Dominated by mpfr_mul for squaring
   - Fractional part extraction (mpfr_frac) is particularly expensive

2. **Cryptographic Mixing** (~20% when enabled)
   - libsodium ChaCha20 generation
   - Modular addition or XOR operations
   - Periodic reseeding

3. **Thread Safety** (~10%)
   - Mutex acquisition/release
   - Thread-local storage access
   - Memory barriers for synchronization

4. **Buffer Management** (~5%)
   - Buffer refill operations
   - Memory copying
   - Position tracking

5. **Error Checking & Validation** (~5%)
   - Parameter validation
   - NaN/infinity checks
   - Range validation

### 12.4 Optimization Opportunities

#### 12.4.1 Precision Tuning

The most effective optimization is reducing MPFR precision:

- 53-bit (double): Baseline performance
- 128-bit: ~2x slower than 53-bit
- 256-bit: ~4x slower than 53-bit
- 512-bit: ~8x slower than 53-bit

#### 12.4.2 Batch Generation

Generating numbers in batches amortizes overhead:

```r
# Inefficient: one at a time
for(i in 1:n) { x[i] <- generatePRNG(1) }

# Efficient: batch generation
x <- generatePRNG(n)
```

#### 12.4.3 Disabling Optional Features

When cryptographic security isn't required:

```r
config <- list(
  use_crypto_mixing = FALSE,    # Disable crypto mixing
  use_threading = FALSE,        # Disable thread safety if single-threaded
  buffer_size = 100000         # Larger buffer for better performance
)
```

### 12.5 Performance vs. Security Trade-off

The 50x performance penalty is a deliberate design choice that provides:

1. **Cryptographic-grade randomness**: Suitable for security applications
2. **Arbitrary precision control**: Can generate numbers with thousands of bits of precision
3. **Mathematical rigor**: Based on proven chaotic dynamical systems
4. **Enhanced unpredictability**: Multiple layers of randomization

For applications where these properties are valuable, the performance cost is justified. For general statistical sampling, standard generators remain more appropriate.

### 12.6 Future Performance Improvements

Potential optimizations that could be explored:

1. **SIMD Parallelization**: Process multiple QI sequences in parallel using vector instructions
2. **GPU Acceleration**: Massive parallelism for batch generation
3. **Fixed-point Arithmetic**: For specific precision requirements, fixed-point could be faster
4. **JIT Compilation**: Compile parameter-specific optimized code at runtime
5. **Hardware PRNG Integration**: Use hardware random sources for mixing instead of libsodium

## 13. Statistical Test Algorithms

### 13.1 Gap Test

The gap test examines the distribution of gaps between occurrences of values within a specified range. For a truly random sequence, these gaps should follow a geometric distribution.

#### 13.1.1 Algorithm

1. **Define target range**: Default is [α, β] = [0.3, 0.7]
2. **Identify positions**: Find all indices where values fall within [α, β]
3. **Calculate gaps**: Compute differences between consecutive positions
4. **Expected distribution**: For uniform random data, gaps follow a geometric distribution with parameter p = β - α

#### 13.1.2 Mathematical Foundation

For a sequence of uniform random numbers, the probability that a value falls in [α, β] is:

```
p = β - α
```

The probability of a gap of length k is:

```
P(gap = k) = (1-p)^(k-1) * p
```

This is the geometric distribution, representing the number of trials until the first success.

#### 13.1.3 Implementation Details

The test uses chi-squared goodness-of-fit to compare observed gap frequencies with expected geometric distribution:

```r
# Expected frequencies for gaps of length 1, 2, ..., max_gap
expected_freq[k] = n_gaps * (1-p)^(k-1) * p

# For the last bin (gaps ≥ max_gap)
expected_freq[max_gap] = n_gaps * (1-p)^(max_gap-1)

# Chi-squared statistic
χ² = Σ((observed[k] - expected[k])²/expected[k])
```

### 13.2 Spectral Test

The spectral test analyzes the frequency domain characteristics of the random sequence using the periodogram and tests whether the spectral densities follow the expected distribution for white noise.

#### 13.2.1 Algorithm

1. **Compute periodogram**: Use Fast Fourier Transform (FFT) to calculate power spectral density
2. **Normalize spectrum**: Scale spectral values by their mean
3. **Expected distribution**: For white noise, normalized spectral densities follow an exponential distribution with rate parameter 1
4. **Test goodness-of-fit**: Use Kolmogorov-Smirnov test to compare with exponential(1) distribution

#### 12.2.2 Mathematical Foundation

For a truly random sequence (white noise), the periodogram ordinates are approximately:

- Independent
- Exponentially distributed with mean equal to the true spectral density

After normalization by the mean, they follow an exponential distribution with rate parameter 1:

```
f(x) = e^(-x) for x ≥ 0
```

#### 12.2.3 Implementation Details

```r
# Compute spectrum using R's spectrum function
spec_result <- spectrum(x, method = "pgram", plot = FALSE)

# Normalize by mean
scaled_spec <- spec_result$spec / mean(spec_result$spec)

# KS test against exponential(1)
ks_result <- ks.test(scaled_spec, "pexp", rate = 1)
```

The Kolmogorov-Smirnov test statistic measures the maximum distance between the empirical distribution function of the scaled spectral values and the theoretical exponential CDF.

#### 12.2.4 Interpretation

- **High p-value**: Spectral characteristics consistent with white noise
- **Low p-value**: Presence of periodic patterns or non-random structure
- **Peak-to-mean ratio**: Additional diagnostic showing the strength of any dominant frequency
